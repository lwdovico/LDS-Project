{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f70e1942",
   "metadata": {},
   "source": [
    "# Setting up the starting time of execution\n",
    "In order to measure the total time of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e33c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now() # just to measure total execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee7801",
   "metadata": {},
   "source": [
    "# PREPROCESSING\n",
    "As external library used we only ***re*** to split according to a regular expression pattern and ***pycountry_convert*** to fetch the countries and continents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0e0dd",
   "metadata": {},
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a814410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to import the csv file into python\n",
    "def import_csv(file_name):\n",
    "    \n",
    "    with open(file_name) as f:\n",
    "        ds = f.readlines()\n",
    "        \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e0ad64",
   "metadata": {},
   "source": [
    "### Adjusting the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02178460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#function to clean and split a string from the csv format to a list of columns\n",
    "def adjust_row(string):\n",
    "    #splitting elements in the list when encountering a comma or a group delimited by quotes\n",
    "    splitted_string = re.split(r',|\"([^\"]*)\"', string.rstrip('\\n'))\n",
    "    \n",
    "    #I have some None elements because I matched two expression and the second (within quotes) return mostly None\n",
    "    #when it doesn't return None it returns empty string delimiting the match (because I am splitting)\n",
    "    #thus I filter None and remove all this stuff\n",
    "    filtered_row = list(filter(None, splitted_string))\n",
    "    \n",
    "    return filtered_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c750a3",
   "metadata": {},
   "source": [
    "### Getting a clean list from the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426a4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get a list of lists from a csv dataset\n",
    "def list_from_csv(ds, header):\n",
    "    new_rows = list()\n",
    "\n",
    "    for row in ds[1:]:\n",
    "        #clean the row\n",
    "        adjusted_row = adjust_row(row)\n",
    "        #check if the columns per row corresponds to the header's columns\n",
    "        assert len(adjusted_row) == len(header), f'{adjusted_row}\\n\\nThe length of the row must be equal to the length of the header!'\n",
    "\n",
    "        new_rows.append(adjusted_row)\n",
    "    return new_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f264b1",
   "metadata": {},
   "source": [
    "### Function to import and process everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819fd01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapping the functions above to read the csv properly, it returns the header and the rows of the dataset\n",
    "def read_csv(file_name):\n",
    "    ds = import_csv(file_name)\n",
    "    header = adjust_row(ds[0])\n",
    "    fixed_rows = list_from_csv(ds, header)\n",
    "    return header, fixed_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f149b7a1",
   "metadata": {},
   "source": [
    "### Creating the column index from the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf9dc67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function to get the index of the columns\n",
    "def header_idx(header):\n",
    "    #to retrieve the index of the column from its name\n",
    "    header_dict = dict([(feat, n) for n, feat in enumerate(header)])\n",
    "    return header_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8c043",
   "metadata": {},
   "source": [
    "### List the column values from the index of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01bc066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract a single column from a list of lists by inputting the index\n",
    "def extract_col(rows, idx):\n",
    "    return [row[idx] for row in rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa6f507",
   "metadata": {},
   "source": [
    "### Get the DataFrame into a Dictionary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e998dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get a dictionary with keys the column name in the header\n",
    "#and as values the correspondeing columns (in a list format)\n",
    "\n",
    "def dict_from_header(header, rows_ds):\n",
    "    header_dict = header_idx(header) #get index from the header\n",
    "    dict_columns = dict()\n",
    "\n",
    "    #for every column get its index and extract its rows\n",
    "    for key in header_dict.keys():\n",
    "        idx = header_dict[key] #get index of col\n",
    "        dict_columns[key] = extract_col(rows_ds, idx) #extract column's values\n",
    "        \n",
    "    return dict_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "355e8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final wrapper to import and preprocess the csv directly into a dictionary\n",
    "#it can also return the header if needed\n",
    "\n",
    "def preprocess_csv_to_dict(file_name, get_header = False):\n",
    "    header, new_rows = read_csv(file_name) #preprocess and read the file\n",
    "    dict_columns = dict_from_header(header, new_rows) #getting the proper dataframe\n",
    "    \n",
    "    if get_header == True:\n",
    "        header_dict = header_idx(header) #to look at the index of the columns\n",
    "        return dict_columns, header_dict\n",
    "    \n",
    "    return dict_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c9b7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_columns = preprocess_csv_to_dict('answerdatacorrect.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7694a9",
   "metadata": {},
   "source": [
    "### Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6562576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the dataset in the dictionary format and the columns for which a table is requested\n",
    "#multiple coluns are accepted, in order to allow creating tables with multiple columns\n",
    "\n",
    "def unify_rows(dict_columns, *columns_to_merge):\n",
    "    merging = list()\n",
    "    \n",
    "    #for every column to merge\n",
    "    for col in columns_to_merge:\n",
    "        row_of_col = dict_columns[col] #get the rows\n",
    "        merging.append(row_of_col) #append the rows to a list\n",
    "    \n",
    "    return zip(*merging) #zip the list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "741dcf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a table from multiple columns\n",
    "def gen_table(dict_columns, *columns):\n",
    "    table_records = list(unify_rows(dict_columns, *columns)) #get the table of records\n",
    "    return [columns] + table_records #returns the full table with the header and the records\n",
    "\n",
    "#it is the same as before but it accepts a list of columns instead of multiple column parameters\n",
    "def gen_table_from_list(dict_columns, columns):\n",
    "    table_records = list(unify_rows(dict_columns, *columns))\n",
    "    return [columns] + table_records\n",
    "\n",
    "#it gets the table of distinct elements and it returns it sorted\n",
    "def gen_table_distinct(dict_columns, *columns):\n",
    "    #here a set is created, then it is made as a list in order to sort it\n",
    "    table_records = sorted(list(set(unify_rows(dict_columns, *columns))))\n",
    "    #finally the header is added\n",
    "    return [columns] + table_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c6b81b",
   "metadata": {},
   "source": [
    "## Geography Table (create Primary Keys and Write CSVs Functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57590596",
   "metadata": {},
   "source": [
    "There is a perfect correspondence between RegionId and CountryCode, thus the RegionId is probably a CountryId instead, and I don't need it in the data I will upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "113c3ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RegionId', 'CountryCode'),\n",
       " ('1', 'au'),\n",
       " ('10', 'uk'),\n",
       " ('11', 'us'),\n",
       " ('2', 'be'),\n",
       " ('3', 'ca'),\n",
       " ('4', 'de'),\n",
       " ('5', 'es'),\n",
       " ('6', 'fr'),\n",
       " ('7', 'ie'),\n",
       " ('8', 'it'),\n",
       " ('9', 'nz')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_table_distinct(dict_columns, 'RegionId', 'CountryCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d802c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_geo_tab = gen_table(dict_columns, 'Region', 'CountryCode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12143b8",
   "metadata": {},
   "source": [
    "### Mapping Continents to the Country Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ca1f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc\n",
    "\n",
    "#function to convert the alpha2 code to the continent\n",
    "def country_to_continent(country_alpha2):\n",
    "    country_alpha2 = country_alpha2.upper() #making the country code uppercase\n",
    "    \n",
    "    #correcting the uk to gb (as it is accepted by the library)\n",
    "    if country_alpha2 == 'UK':\n",
    "        country_alpha2 = 'GB'\n",
    "        \n",
    "    #get continent code from country code\n",
    "    country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "    #get continent name from continent code\n",
    "    country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "    return country_continent_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49657741",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = set([x[1] for x in temp_geo_tab[1:]])\n",
    "## {'au', 'be', 'ca', 'de', 'es', 'fr', 'ie', 'it', 'nz', 'uk', 'us'}\n",
    "map_country_to_cont = {cc : country_to_continent(cc) for cc in country_codes}\n",
    "## {'es': 'Europe', 'ie': 'Europe', 'ca': 'North America', ..., 'au': 'Oceania'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f50a0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes_list = [x[1] for x in temp_geo_tab[1:]]\n",
    "## ['es', 'fr', 'uk', ..., 'de', 'de', 'au']\n",
    "continent_column = list(map(lambda x: map_country_to_cont[x], country_codes_list))\n",
    "## ['Europe', 'Europe', 'Europe', ...,'Europe', 'Europe', 'Oceania']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14160ac5",
   "metadata": {},
   "source": [
    "### Mapping Country Names to the Country Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4116cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_to_country_name(country_alpha2):\n",
    "    country_alpha2 = country_alpha2.upper() #making the country code uppercase\n",
    "    \n",
    "    #correcting the uk to gb (as it is accepted by the library)\n",
    "    if country_alpha2 == 'UK':\n",
    "        country_alpha2 = 'GB'\n",
    "        \n",
    "    #get country name from country code\n",
    "    country_name = pc.country_alpha2_to_country_name(country_alpha2)\n",
    "    return country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c174bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_country_to_name = {cc : country_to_country_name(cc) for cc in country_codes}\n",
    "## {'us': 'United States', 'nz': 'New Zealand', 'fr': 'France', ...,'it': 'Italy', 'au': 'Australia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cad9e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name_column = list(map(lambda x: map_country_to_name[x], country_codes_list))\n",
    "## ['Germany', 'United States', 'Ireland', ...,'Ireland', 'Germany', 'United Kingdom']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e34a6b",
   "metadata": {},
   "source": [
    "### Add the Continent and CountryName Columns to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e1e1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_columns['Continents'] = continent_column\n",
    "dict_columns['CountryName'] = country_name_column\n",
    "\n",
    "#geography_table = gen_table(dict_columns, 'Region', 'CountryCode', 'Continents')\n",
    "#[('Region', 'CountryCode', 'Continents'), ('galicia', 'es', 'Europe'), ('upland france', 'fr', 'Europe'), ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a71d0ae",
   "metadata": {},
   "source": [
    "### Create Primary Key Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e36ed843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the table and the primary key column's name\n",
    "#it adds the primary key to the table as its first column\n",
    "\n",
    "def set_primary_key(table, name_primary_key):\n",
    "    \n",
    "    #get the primary key column (with header the input name) by ranging across the rows\n",
    "    id_col = [name_primary_key] + [str(i) for i in range(1, len(table)+1)]\n",
    "    #zipping the primary key and the previous table, it has to be unzipped though\n",
    "    table_to_unzip = list(zip(id_col, table))\n",
    "    #get the number of columns (length of a row)\n",
    "    len_rows = len(table[0])\n",
    "    \n",
    "    #the output\n",
    "    outres = list()\n",
    "\n",
    "    #for each row in the table\n",
    "    for row in table_to_unzip:\n",
    "        #get the first element (the primary key)\n",
    "        unzipped = [row[0]]\n",
    "        \n",
    "        #loop across the second element with the original columns\n",
    "        for n in range(len_rows):\n",
    "            #add the columns to the unzipped table\n",
    "            unzipped.append(row[1][n])\n",
    "            \n",
    "        #add the current row to the output\n",
    "        outres.append(tuple(unzipped))\n",
    "        \n",
    "    return outres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "453f0de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_key_from_cols(table, name_primary_key, *idx):\n",
    "    \n",
    "    primary_keys = list()\n",
    "    \n",
    "    for row in table[1:]:\n",
    "        temp_key = row[idx[0]].replace(' ', '-')\n",
    "        for i in idx[1:]:\n",
    "            temp_key += f'-{row[i]}'    \n",
    "        primary_keys.append(temp_key)\n",
    "        \n",
    "    id_col = [name_primary_key] + primary_keys\n",
    "        \n",
    "    table_to_unzip = list(zip(id_col, table))\n",
    "    \n",
    "    len_rows = len(table[0])\n",
    "    \n",
    "    outres = list()\n",
    "\n",
    "    for row in table_to_unzip:\n",
    "        unzipped = [row[0]]\n",
    "        for n in range(len_rows):\n",
    "            unzipped.append(row[1][n])\n",
    "        outres.append(tuple(unzipped))\n",
    "        \n",
    "    return outres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d12e51e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('geoid', 'Region', 'CountryCode'),\n",
       " ('1', 'mecklenburg-vorpommern', 'de'),\n",
       " ('2', 'south-east usa', 'us'),\n",
       " ('3', 'connaught', 'ie'),\n",
       " ('4', 'north italy', 'it')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_primary_key(temp_geo_tab[:5], 'geoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6d917c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('geoid', 'Region', 'CountryCode'),\n",
       " ('mecklenburg-vorpommern-de', 'mecklenburg-vorpommern', 'de'),\n",
       " ('south-east-usa-us', 'south-east usa', 'us'),\n",
       " ('connaught-ie', 'connaught', 'ie'),\n",
       " ('north-italy-it', 'north italy', 'it')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_key_from_cols(temp_geo_tab[:5], 'geoid', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2002a920",
   "metadata": {},
   "source": [
    "### Writing the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb53cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it makes the csv to a list of strings (from list of lists)\n",
    "def make_string_csv(table):\n",
    "    output = list()\n",
    "    \n",
    "    #for each row join the columns\n",
    "    for row in table:\n",
    "        row = list(row) #make list from tuple\n",
    "        output.append(','.join(row)+'\\n') #join list of cols and add commas and new line\n",
    "        \n",
    "    return output\n",
    "\n",
    "#input a name of the file and the table to save\n",
    "def create_csv(name_file, table):\n",
    "    \n",
    "    #open the file to write\n",
    "    file_opened = open(name_file, 'w')\n",
    "\n",
    "    #write each row\n",
    "    for row in make_string_csv(table):\n",
    "        file_opened.write(row)\n",
    "\n",
    "    #close the file\n",
    "    file_opened.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01445b",
   "metadata": {},
   "source": [
    "### Saving the Geography Final Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc5ceaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "geography_table = gen_table_distinct(dict_columns, 'Region', 'CountryCode', 'CountryName', 'Continents')\n",
    "geography_table = set_primary_key(geography_table, 'GeoId')\n",
    "create_csv('Geography.csv', geography_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a29b93",
   "metadata": {},
   "source": [
    "### Get DataFrame Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04808028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the length of the dataframe by extracting and counting elements in the first column\n",
    "def get_len_df(dict_df):\n",
    "    return len(dict_df[list(dict_columns.keys())[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fb2cc4",
   "metadata": {},
   "source": [
    "## Computing the IsCorrect Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec6abd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538835"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_df = get_len_df(dict_columns)\n",
    "len_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b12e488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['QuestionId', 'UserId', 'AnswerId', 'CorrectAnswer', 'AnswerValue', 'Gender', 'DateOfBirth', 'PremiumPupil', 'DateAnswered', 'Confidence', 'GroupId', 'QuizId', 'SchemeOfWorkId', 'SubjectId', 'RegionId', 'Region', 'CountryCode', 'Continents', 'CountryName'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "819d1150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', '2'),\n",
       " ('4', '4'),\n",
       " ('4', '4'),\n",
       " ('4', '2'),\n",
       " ('4', '2'),\n",
       " ('4', '4'),\n",
       " ('4', '4'),\n",
       " ('4', '4'),\n",
       " ('4', '4'),\n",
       " ('4', '4')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(dict_columns['CorrectAnswer'], dict_columns['AnswerValue']))[15:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a1e88",
   "metadata": {},
   "source": [
    "With a loop through the length of the list checking if the rows with the same index have identical values and return not a boolean but 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cbe737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it checks if the answer value is correct and it adds 0 if not or 1 if it is\n",
    "iscorrect = list()\n",
    "\n",
    "for n in range(len_df):\n",
    "    first_col = dict_columns['CorrectAnswer'][n]\n",
    "    second_col = dict_columns['AnswerValue'][n]\n",
    "    \n",
    "    boolean_val = first_col == second_col\n",
    "    iscorrect.append(str(int(boolean_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae6d88fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iscorrect[50:62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4bf55c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iscorrect) == len_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44effaa1",
   "metadata": {},
   "source": [
    "### Adding IsCorrect to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0be61770",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_columns['IsCorrect'] = iscorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e5f081",
   "metadata": {},
   "source": [
    "## Subject Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8fcfa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column for the subjectid\n",
    "format_sub_col_to_list = list()\n",
    "\n",
    "for x in dict_columns['SubjectId']:\n",
    "    #make the string a list\n",
    "    adjust_split = x.strip('][').split(', ')\n",
    "    \n",
    "    #append the values to the new column as integer\n",
    "    format_sub_col_to_list.append([int(sub_id) for sub_id in adjust_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4af7fdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 101, 115, 342],\n",
       " [3, 101, 115, 342],\n",
       " [3, 101, 115, 342],\n",
       " [3, 101, 115, 342],\n",
       " [3, 101, 115, 342]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_sub_col_to_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b95a5c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 32, 36, 39, 44, 49, 59, 165, 222, 230, 233]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(format_sub_col_to_list, key=lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad5e3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the csv of the subject metadata to a dictionary\n",
    "meta = preprocess_csv_to_dict('subject_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "386efbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ï»¿SubjectId', 'Name', 'ParentId', 'Level'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c0a4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing the wrong naming of the first column\n",
    "meta['SubjectId'] = meta['ï»¿SubjectId']\n",
    "del meta['ï»¿SubjectId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fc32a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the a dictionary to call the subject description, parent and level from its single subject code\n",
    "subject_caller = dict(zip([int(x) for x in meta['SubjectId']], \n",
    "                          list(zip(meta['Name'], meta['ParentId'], [int(x) for x in meta['Level']]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08fc97c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, ('Maths', 'NULL', 0)),\n",
       " (32, ('Number', '3', 1)),\n",
       " (33, ('BIDMAS', '144', 3)),\n",
       " (34, ('Upper and Lower Bounds', '141', 3)),\n",
       " (35, ('Calculator Use', '32', 2)),\n",
       " (36, ('Decimals', '32', 2)),\n",
       " (37, ('Factors, Multiples and Primes', '32', 2)),\n",
       " (38, ('Fractions, Decimals and Percentage Equivalence', '32', 2)),\n",
       " (39, ('Fractions', '32', 2)),\n",
       " (40, ('Indices, Powers and Roots', '32', 2))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(subject_caller.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773de5c",
   "metadata": {},
   "source": [
    "### Reorder subject lists according to level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f100c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reordering the original list according to the parent levels (ascending order)\n",
    "new_formatted_subject_col = list()\n",
    "for row in format_sub_col_to_list:\n",
    "    #sorting the rows according to the level (third element of the value in the dict)\n",
    "    new_row = sorted(row, key=lambda x: subject_caller[x][2])\n",
    "    new_formatted_subject_col.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a340f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 101, 342, 115],\n",
       " [3, 101, 342, 115],\n",
       " [3, 101, 342, 115],\n",
       " [3, 101, 342, 115],\n",
       " [3, 101, 342, 115],\n",
       " [3, 101, 342, 115],\n",
       " [3, 101, 342, 115],\n",
       " [3, 101, 342, 115],\n",
       " [3, 101, 342, 115],\n",
       " [3, 101, 342, 115]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_formatted_subject_col[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbb7d9",
   "metadata": {},
   "source": [
    "### Subject Description\n",
    "Writing only the level indicated in the SubjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "469fea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_column = list()\n",
    "\n",
    "for row in new_formatted_subject_col:\n",
    "    description_row = list()\n",
    "    \n",
    "    #for each subject in the subject id column\n",
    "    for col_val in row:\n",
    "        #unpack the values in the dictionary\n",
    "        description, parent, level = subject_caller[col_val]\n",
    "        \n",
    "        #adding the description of the each value to the row\n",
    "        new_row = f'{description}({col_val})'\n",
    "        \n",
    "        #ppend the row to the description row\n",
    "        description_row.append(new_row)\n",
    "        \n",
    "    #append the new description to the new description column\n",
    "    description_column.append(description_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf74a4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maths(3)',\n",
       " 'Number(32)',\n",
       " 'Algebra(49)',\n",
       " 'Decimals(36)',\n",
       " 'Fractions(39)',\n",
       " 'Percentages(44)',\n",
       " 'Inequalities(59)',\n",
       " 'Inequalities on Number Lines(165)',\n",
       " 'Ordering Decimals(222)',\n",
       " 'Adding and Subtracting Fractions(230)',\n",
       " 'Percentages of an Amount(233)']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(description_column, key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0fd454c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#adjusting the format of the description column to a single string\n",
    "\n",
    "subject_column = list()\n",
    "\n",
    "for row in description_column:\n",
    "    #get the first element and add the quotation mark\n",
    "    subjects = f'\"{row[0]}'\n",
    "    \n",
    "    #get the other elements and add them in sequence\n",
    "    for el in row[1:]:\n",
    "        subjects += f' - {el}'\n",
    "    \n",
    "    #add a last quotation mark to the end of the new row\n",
    "    subjects += '\"'\n",
    "    #append the new description to the final subject column\n",
    "    subject_column.append(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1521108b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Maths(3)',\n",
       " 'Number(32)',\n",
       " 'Algebra(49)',\n",
       " 'Decimals(36)',\n",
       " 'Fractions(39)',\n",
       " 'Percentages(44)',\n",
       " 'Inequalities(59)',\n",
       " 'Inequalities on Number Lines(165)',\n",
       " 'Ordering Decimals(222)',\n",
       " 'Adding and Subtracting Fractions(230)',\n",
       " 'Percentages of an Amount(233)\"']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([x.split(' - ') for x in subject_column], key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21f67f97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Maths(3) - Number(32) - Decimals(36) - Fractions, Decimals and Percentage Equivalence(38) - Percentages(44) - Multiplying and Dividing with Decimals(224) - Percentages of an Amount(233) - Percentage Increase and Decrease(234) - Converting between Decimals and Percentages(239)\"'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(subject_column, key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebbc075f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(subject_column, key=lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34530f09",
   "metadata": {},
   "source": [
    "### Storing to DF and Saving the Subject Table into a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "113a0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_columns['Description'] = subject_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c457a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_table = gen_table_distinct(dict_columns, 'Description')\n",
    "subject_table = set_primary_key(subject_table, 'SubjectId')\n",
    "create_csv('Subject.csv', subject_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d056cf5",
   "metadata": {},
   "source": [
    "## Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "863ebbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['QuestionId', 'UserId', 'AnswerId', 'CorrectAnswer', 'AnswerValue', 'Gender', 'DateOfBirth', 'PremiumPupil', 'DateAnswered', 'Confidence', 'GroupId', 'QuizId', 'SchemeOfWorkId', 'SubjectId', 'RegionId', 'Region', 'CountryCode', 'Continents', 'CountryName', 'IsCorrect', 'Description'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_columns.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef518aa3",
   "metadata": {},
   "source": [
    "### Get Date Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80e03925",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_date = gen_table(dict_columns, 'DateOfBirth', 'DateAnswered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d09216c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538836"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(double_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "296a4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_clean = dict_columns['DateAnswered']\n",
    "space_pointer = date_to_clean[0].find(' ') #get the space position to discard the time\n",
    "date_cleaned = [x[:space_pointer] for x in date_to_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5e11785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the two date columns into one\n",
    "single_col_date = ['Dates'] + dict_columns['DateOfBirth'] + date_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df3a5619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077671"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(single_col_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca3695",
   "metadata": {},
   "source": [
    "### Adjust Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8e4207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year, month, day, quarter = list(), list(), list(), list()\n",
    "\n",
    "dict_temp_quarter = {}\n",
    "\n",
    "#write a temporary dictionary for each month pertaining to a quarter\n",
    "for i in range(1, 5):\n",
    "    dict_temp_quarter[f'Q{i}'] = [3*i-j for j in range(2, -1, -1)]\n",
    "    #{'Q1': [1, 2, 3], 'Q2': [4, 5, 6], 'Q3': [7, 8, 9], 'Q4': [10, 11, 12]}\n",
    "    \n",
    "#reverse the previous dictionary unpacking each month into a key with its respective quarter\n",
    "dict_quarters = dict()\n",
    "for k, v in dict_temp_quarter.items():\n",
    "    for i in range(len(v)):\n",
    "        dict_quarters[v[i]] = k\n",
    "        #{1: 'Q1', 2: 'Q1', 3: 'Q1', \n",
    "        # 4: 'Q2', 5: 'Q2', 6: 'Q2', \n",
    "        # 7: 'Q3', 8: 'Q3', 9: 'Q3',\n",
    "        # 10: 'Q4', 11: 'Q4', 12: 'Q4'}\n",
    "\n",
    "for row in single_col_date[1:]:\n",
    "    #split the single date according to each dash -\n",
    "    splitted_date = row.split('-')\n",
    "    \n",
    "    #add the year to its own column\n",
    "    year.append(splitted_date[0])\n",
    "    #add the year-month to the month column\n",
    "    month.append(splitted_date[0]+'-'+splitted_date[1])\n",
    "    #add the full date to the day column\n",
    "    day.append(row)\n",
    "    #add the year-quarter to its column, the quarter is retrieved by dict_quarters[month]\n",
    "    quarter.append(splitted_date[0]+'-'+dict_quarters[int(splitted_date[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c93e8fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077670"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd8399",
   "metadata": {},
   "source": [
    "### Compile new Date Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c3f18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_date = tuple(['Dates', 'Year', 'Month', 'Day', 'Quarter'])\n",
    "date_without_header = single_col_date[1:]\n",
    "data_date = sorted(list(set(zip(date_without_header, year, month, day, quarter))))\n",
    "\n",
    "date_table = [header_date]+data_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e987737d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dates', 'Year', 'Month', 'Day', 'Quarter'),\n",
       " ('2000-11-01', '2000', '2000-11', '2000-11-01', '2000-Q4'),\n",
       " ('2001-03-01', '2001', '2001-03', '2001-03-01', '2001-Q1'),\n",
       " ('2001-04-01', '2001', '2001-04', '2001-04-01', '2001-Q2'),\n",
       " ('2001-10-01', '2001', '2001-10', '2001-10-01', '2001-Q4'),\n",
       " ('2001-11-01', '2001', '2001-11', '2001-11-01', '2001-Q4'),\n",
       " ('2002-01-01', '2002', '2002-01', '2002-01-01', '2002-Q1'),\n",
       " ('2002-03-01', '2002', '2002-03', '2002-03-01', '2002-Q1'),\n",
       " ('2002-06-01', '2002', '2002-06', '2002-06-01', '2002-Q2'),\n",
       " ('2002-07-01', '2002', '2002-07', '2002-07-01', '2002-Q3')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_table[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a72bc5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73e22b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(zip(date_without_header, year, month, day, quarter))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7ed3b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13631"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#date of birth and user Id together\n",
    "len(set(gen_table(dict_columns, 'DateOfBirth', 'UserId')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375281c",
   "metadata": {},
   "source": [
    "### Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37f6fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_table = set_primary_key(date_table, 'DateId')\n",
    "create_csv('Date.csv', date_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcecef93",
   "metadata": {},
   "source": [
    "## Organization (quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "320fefab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['QuestionId', 'UserId', 'AnswerId', 'CorrectAnswer', 'AnswerValue', 'Gender', 'DateOfBirth', 'PremiumPupil', 'DateAnswered', 'Confidence', 'GroupId', 'QuizId', 'SchemeOfWorkId', 'SubjectId', 'RegionId', 'Region', 'CountryCode', 'Continents', 'CountryName', 'IsCorrect', 'Description'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "439bf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "organization_table = gen_table_distinct(dict_columns, 'GroupId', 'QuizId', 'SchemeOfWorkId')\n",
    "organization_table = set_primary_key(organization_table, 'OrganizationId')\n",
    "create_csv('Organization.csv', organization_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb5952dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24641"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(organization_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f1fe6",
   "metadata": {},
   "source": [
    "## User (Merging Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1130c55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geography_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "994ce707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subject_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7914d96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7cf62203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24641"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(organization_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "100a80cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['QuestionId', 'UserId', 'AnswerId', 'CorrectAnswer', 'AnswerValue', 'Gender', 'DateOfBirth', 'PremiumPupil', 'DateAnswered', 'Confidence', 'GroupId', 'QuizId', 'SchemeOfWorkId', 'SubjectId', 'RegionId', 'Region', 'CountryCode', 'Continents', 'CountryName', 'IsCorrect', 'Description'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_columns.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b00c52",
   "metadata": {},
   "source": [
    "### Mapping Function\n",
    "Used to map the primary keys created where the corresponding values appears in other tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b3192574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to map from a specific table's column mapping sources a destination column\n",
    "#input are: \n",
    "#            the table considered, the column to map and\n",
    "#            multiple parameters indicating the single columns to map on\n",
    "\n",
    "\n",
    "#converting the feature to map on by joining the columns into a single string per row\n",
    "def join_multi_columns(*list_of_lists):\n",
    "    #if it is a single column it returns it without alteration, otherwise it joins them with a dash in between\n",
    "    return ['-'.join(list(el)) if type(el) != str else el for el in zip(*list_of_lists)]\n",
    "\n",
    "def map_values(table, destination_column, *col_mapping_sources):\n",
    "    \n",
    "    #get the header of the table in order to have the corresponding indexes\n",
    "    header_index = header_idx(table[0])\n",
    "    #getting the list of indexes inserted in the \n",
    "    idx_source_columns = [header_index[col] for col in col_mapping_sources]\n",
    "    \n",
    "    list_id = [x[0] for x in table[1:]] #getting the ids (conveniently always at the first position)\n",
    "    \n",
    "    #getting the stuff to merge on (it must have corresponding values in the destination column)\n",
    "    #I used the extract col function which is just a loop that extract a column according to a index\n",
    "    #Then I loop across all the indexes to consider (retrieved by the parameters in col_mapping_sources)\n",
    "    list_feat_origin = [extract_col(table[1:], idx) for idx in idx_source_columns]\n",
    "    #If multiple col_mapping_sources: -> list_feat_origin is a list of lists\n",
    "    \n",
    "    #joining the features considered into a single one\n",
    "    #the same thing should be applied on multiple destination_column (only one input is accepted here though)\n",
    "    list_feat = join_multi_columns(*list_feat_origin)\n",
    "    \n",
    "    #creating the dictionary with the structure value_to_map:primary_key\n",
    "    id_dict = {feat : idx for idx, feat in zip(list_id, list_feat)}\n",
    "    \n",
    "    try:\n",
    "        #mapped column result\n",
    "        mapped_col = list(map(lambda x: id_dict[x], destination_column))\n",
    "    except:\n",
    "        #if an error is raised, probably there is no correspondence between the col_mapping_sources and destination\n",
    "        raise Exception('The columns to map must have exact correspondence to the destination column')\n",
    "    \n",
    "    return mapped_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a067ef9",
   "metadata": {},
   "source": [
    "### GeoId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9644b01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GeoId', 'Region', 'CountryCode', 'CountryName', 'Continents')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geography_table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2e75476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoid = map_values(geography_table, dict_columns['Region'], 'Region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d5a1205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(geoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9d08f301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538835"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d40c0",
   "metadata": {},
   "source": [
    "### DateId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "15b75e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13630"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dict_columns['UserId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "77237255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538835"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_columns['DateOfBirth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "81ea23c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538835"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date_cleaned) #date answered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739213fb",
   "metadata": {},
   "source": [
    "### Mapping on DateOfBirth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17cbc74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateid_birth = map_values(date_table, dict_columns['DateOfBirth'], 'Dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b856a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538835"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dateid_birth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "13eda09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "84121654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dateid_birth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a467de5",
   "metadata": {},
   "source": [
    "### Mapping on DateAnswered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "52664f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateid_answered = map_values(date_table, date_cleaned, 'Dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "44fd2fe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538835"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dateid_answered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf1635c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "99a86b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dateid_answered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d3f4e2",
   "metadata": {},
   "source": [
    "### Getting UserId Table\n",
    "\n",
    "Non torna il numero di user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cfc10a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_header = ('UserId', 'DateId', 'GeoId', 'Gender')\n",
    "user_table_zip = list(zip(dict_columns['UserId'], dateid_birth, geoid, dict_columns['Gender']))\n",
    "user_table_full = [user_header] + user_table_zip\n",
    "\n",
    "#making the zip a set to remove duplicates, then again a list to sort it and add the header\n",
    "user_table_distinct = [user_header] + sorted(list(set(user_table_zip)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e8cabbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538836"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_table_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ee467b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13631"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_table_distinct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "12ae3b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13630"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dict_columns['UserId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "39fe3d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13630"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(zip(dict_columns['UserId'], dateid_birth, dict_columns['Gender']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "66539dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_table = user_table_distinct\n",
    "create_csv('User.csv', user_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16043b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13631"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a142d462",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('UserId', 'DateId', 'GeoId', 'Gender'),\n",
       " ('1', '53', '14', '2'),\n",
       " ('100006', '28', '31', '2'),\n",
       " ('100010', '44', '51', '1'),\n",
       " ('10002', '31', '13', '1'),\n",
       " ('100040', '28', '36', '1'),\n",
       " ('100042', '67', '23', '2'),\n",
       " ('100059', '57', '12', '1'),\n",
       " ('100065', '29', '9', '1'),\n",
       " ('100071', '32', '33', '1')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_table[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890b094",
   "metadata": {},
   "source": [
    "## Writing the Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6678906c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('UserId', 'DateId', 'GeoId', 'Gender'), ('1', '53', '14', '2')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_table[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "46ce9bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GeoId', 'Region', 'CountryCode', 'CountryName', 'Continents'),\n",
       " ('1', 'andalucia', 'es', 'Spain', 'Europe')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geography_table[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5fdb2512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OrganizationId', 'GroupId', 'QuizId', 'SchemeOfWorkId'),\n",
       " ('1', '10019', '1127', '8386.0')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organization_table[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c2271a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SubjectId', 'Description'),\n",
       " ('1',\n",
       "  '\"Maths(3) - Advanced Pure(119) - Functions(146) - Composite Functions(437)\"')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_table[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ca4c40ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DateId', 'Dates', 'Year', 'Month', 'Day', 'Quarter'),\n",
       " ('1', '2000-11-01', '2000', '2000-11', '2000-11-01', '2000-Q4')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_table[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d0ee43e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['QuestionId', 'UserId', 'AnswerId', 'CorrectAnswer', 'AnswerValue', 'Gender', 'DateOfBirth', 'PremiumPupil', 'DateAnswered', 'Confidence', 'GroupId', 'QuizId', 'SchemeOfWorkId', 'SubjectId', 'RegionId', 'Region', 'CountryCode', 'Continents', 'CountryName', 'IsCorrect', 'Description'])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_columns.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7bb7c",
   "metadata": {},
   "source": [
    "### Map organization Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f24fa91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OrganizationId', 'GroupId', 'QuizId', 'SchemeOfWorkId'),\n",
       " ('1', '10019', '1127', '8386.0')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organization_table[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2131515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "organization_feat = [dict_columns['GroupId'], \n",
    "                     dict_columns['QuizId'], \n",
    "                     dict_columns['SchemeOfWorkId']]\n",
    "\n",
    "org_to_join_on = join_multi_columns(*organization_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5e673c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "organizationid = map_values(organization_table, org_to_join_on, 'GroupId', 'QuizId', 'SchemeOfWorkId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "89d86b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538835"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(organizationid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd8bf8",
   "metadata": {},
   "source": [
    "### Map SubjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "65697400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subject_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d37f450a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['QuestionId', 'UserId', 'AnswerId', 'CorrectAnswer', 'AnswerValue', 'Gender', 'DateOfBirth', 'PremiumPupil', 'DateAnswered', 'Confidence', 'GroupId', 'QuizId', 'SchemeOfWorkId', 'SubjectId', 'RegionId', 'Region', 'CountryCode', 'Continents', 'CountryName', 'IsCorrect', 'Description'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2a81b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectid = map_values(subject_table, dict_columns['Description'], 'Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "10802c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538835"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subjectid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5045a2b",
   "metadata": {},
   "source": [
    "### Add columns to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f49a6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_table = gen_table(dict_columns, \n",
    "                         'AnswerId', \n",
    "                         'QuestionId', \n",
    "                         'AnswerValue', \n",
    "                         'CorrectAnswer', \n",
    "                         'IsCorrect', \n",
    "                         'Confidence', \n",
    "                         'UserId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ea1625d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10192', '10192', '15433', '1222', '2186', '15433']\n",
      "538835\n"
     ]
    }
   ],
   "source": [
    "print(organizationid[:6])\n",
    "print(len(organizationid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "72359caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['239', '239', '201', '262', '392', '197']\n",
      "538835\n"
     ]
    }
   ],
   "source": [
    "print(dateid_answered[:6])\n",
    "print(len(dateid_answered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "98ad3ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['136', '136', '136', '136', '136', '136']\n",
      "538835\n"
     ]
    }
   ],
   "source": [
    "print(subjectid[:6])\n",
    "print(len(subjectid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "545e9b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AnswerId',\n",
       "  'QuestionId',\n",
       "  'AnswerValue',\n",
       "  'CorrectAnswer',\n",
       "  'IsCorrect',\n",
       "  'Confidence',\n",
       "  'UserId'),\n",
       " ('9602029', '16997', '4', '4', '1', '100.0', '17397'),\n",
       " ('9987106', '16997', '4', '4', '1', '100.0', '95904'),\n",
       " ('1185187', '16997', '4', '4', '1', '50.0', '35717'),\n",
       " ('629715', '16997', '4', '4', '1', '100.0', '67433'),\n",
       " ('14856343', '16997', '4', '4', '1', '100.0', '90547')]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_table[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bf22d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to add multiple columns to a table\n",
    "def add_columns(table, *columns):\n",
    "    #zip every columns to a list\n",
    "    zipped_input = list(zip(*columns))\n",
    "    \n",
    "    #get the number of columns\n",
    "    len_rows = len(table[0])\n",
    "    len_zipped = len(zipped_input[0])\n",
    "    \n",
    "    output_table = list()\n",
    "    \n",
    "    #loop across every column\n",
    "    #get the rows of that column\n",
    "    #append to table\n",
    "    #for both table and *columns to add\n",
    "    \n",
    "    #add each column of the original table to the list\n",
    "    for col in range(len_rows):\n",
    "        origin = extract_col(table, col)\n",
    "        output_table.append((origin))\n",
    "    \n",
    "    #add each column of the zipped new columns to the list\n",
    "    for col in range(len_zipped):\n",
    "        origin = extract_col(zipped_input, col)\n",
    "        output_table.append((origin))\n",
    "        \n",
    "    return list(zip(*output_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ee5e880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_organizationid = ['OrganizationId'] + organizationid\n",
    "h_dateid = ['DateId'] + dateid_answered #mapping answer dates on the fact table\n",
    "h_subjectid = ['SubjectId'] + subjectid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b991d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_final = add_columns(answer_table, \n",
    "                           h_organizationid, \n",
    "                           h_dateid, \n",
    "                           h_subjectid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "03b7e9b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538836"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e2416a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538836"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(answer_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5c94d618",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AnswerId',\n",
       "  'QuestionId',\n",
       "  'AnswerValue',\n",
       "  'CorrectAnswer',\n",
       "  'IsCorrect',\n",
       "  'Confidence',\n",
       "  'UserId',\n",
       "  'OrganizationId',\n",
       "  'DateId',\n",
       "  'SubjectId'),\n",
       " ('9602029', '16997', '4', '4', '1', '100.0', '17397', '10192', '239', '136'),\n",
       " ('9987106', '16997', '4', '4', '1', '100.0', '95904', '10192', '239', '136'),\n",
       " ('1185187', '16997', '4', '4', '1', '50.0', '35717', '15433', '201', '136'),\n",
       " ('629715', '16997', '4', '4', '1', '100.0', '67433', '1222', '262', '136'),\n",
       " ('14856343', '16997', '4', '4', '1', '100.0', '90547', '2186', '392', '136')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_final[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7958ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv('Answers.csv', answer_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e73fc36",
   "metadata": {},
   "source": [
    "# LOADING ON THE SERVER\n",
    "To manage the data we used mainly functions written in the previous step and a Class we wrote to upload to the actual server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef29974",
   "metadata": {},
   "source": [
    "This is in the case the upload must be done from preprocessed CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7e3b2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# #listing the csv files in the same folder that do not have data in the name\n",
    "# csv_files = [x for x in os.listdir() if x[-4:] == '.csv' and 'data' not in x]\n",
    "# print(csv_files)\n",
    "\n",
    "# #add the files to a dictionary to have them ready to be uploaded by calling just the file name\n",
    "# tables = dict()\n",
    "# for file_name in csv_files:\n",
    "#     tables[file_name] = preprocess_csv_to_dict(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ad89d",
   "metadata": {},
   "source": [
    "This is in the case the upload is intended to be done with variables created during the preprocessing in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ad4b1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = dict()\n",
    "table_names = ['Geography', 'Subject', 'Organization', 'Date', 'User', 'Answers']\n",
    "\n",
    "# creating a copy of each to run this cell multiple times\n",
    "tables_saved = [geography_table[:], subject_table[:], organization_table[:], date_table[:], user_table[:], answer_final[:]]\n",
    "\n",
    "for table_name, table in zip(table_names, tables_saved):\n",
    "    header = table.pop(0) # getting the header from each table\n",
    "    tables[table_name] = dict_from_header(header, table) #storing each table to a dictionary called tables ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d5c84",
   "metadata": {},
   "source": [
    "## Max length of characters for Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "55cd5da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the length of the subject table to check if it corresponds in the schema\n",
    "len(max(tables['Subject']['Description'], key=lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a07bde",
   "metadata": {},
   "source": [
    "# Upload tables on the Data Warehouse\n",
    "\n",
    "This class enstablish a connection to the server, adjust the table according to the type required by the schema on the server, it drops previous values from the table and then it load the files on the server (committing every 100 records uploaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2d48877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pyodbc\n",
    "import copy\n",
    "\n",
    "#this class will empty the remote table to load the one from a dictionary\n",
    "\n",
    "class Upload_Table():\n",
    "    \n",
    "    def __init__(self, table_dict, table_name):\n",
    "        #to avoid editing the original dictionary (if error occurs)\n",
    "        self.table = copy.deepcopy(table_dict)\n",
    "        #it removes ambiguities in the case of reserved keywords (e.g. User)\n",
    "        self.table_name = \"[\"+table_name+\"]\" \n",
    "        \n",
    "        #Create a connection and a cursor in the database\n",
    "        self.conn = self.get_connection()\n",
    "        self.cursor = self.conn.cursor()\n",
    "        \n",
    "        #adjust the table input in the class to the types in the SQL Server Schema\n",
    "        self.table = self.adjust_types()\n",
    "        \n",
    "        #try to upload the table\n",
    "        try:\n",
    "            self.insert_into_table()\n",
    "            \n",
    "        #close connection if an exception occurs\n",
    "        except Exception as e:\n",
    "            self.cursor.close()\n",
    "            self.conn.close()\n",
    "            raise e\n",
    "            \n",
    "        #close connection if it is a success\n",
    "        self.cursor.close()\n",
    "        self.conn.close()\n",
    "        \n",
    "        #delete the connection variables from the class\n",
    "        del self.cursor\n",
    "        del self.conn\n",
    "        \n",
    "    #function to get the credentials and perform the connection to the database\n",
    "    def get_connection(self):\n",
    "        \n",
    "        #a file with the ip, userid and credentials must be in the same folder\n",
    "        with open('credentials.txt', 'r') as f:\n",
    "            ip, uid, pwd = f.read().splitlines()\n",
    "            \n",
    "        driver = 'ODBC Driver 17 for SQL Server'\n",
    "        self.db = 'Group_10_DB' #the name of the database to which I am operating\n",
    "\n",
    "        conn = pyodbc.connect(f'DRIVER={driver};SERVER=tcp:{ip};DATABASE={self.db};UID={uid};PWD={pwd}')\n",
    "        \n",
    "        return conn\n",
    "    \n",
    "    def adjust_types(self):\n",
    "        self.cursor.execute(f'SELECT * FROM {self.table_name}')\n",
    "        \n",
    "        #using a dictionary to cast the correct types to the data\n",
    "        #the lambda functions is there to cast the correct types\n",
    "        cast_types = {'int': lambda x: int(float(x)), #some strings have values with a dot\n",
    "                      'float': float, \n",
    "                      'str': lambda x: f\"'{str(x)}'\", #string\n",
    "                      'datetime.date': lambda x: f\"'{str(x)}'\",  #date must be passed as a string in explicit queries\n",
    "                      'bool': lambda x: int(float(x))}\n",
    "        \n",
    "        \n",
    "        col_type = dict()\n",
    "\n",
    "        #looping across the information get by the cursor\n",
    "        for name_col, type_col, _, len_char1, len_char2, _, accept_none in self.cursor.description:\n",
    "            #getting the type from the type_col response string\n",
    "            str_type = re.findall(\"'.*'\", str(type_col))[0].strip(\"'\")\n",
    "            #saving the column with the corresponding type to cast into a dictionary\n",
    "            col_type[name_col] = cast_types[str_type]\n",
    "\n",
    "        #get the header of the local table\n",
    "        self.header_table = list(self.table.keys())\n",
    "        #check if the header of the local table corresponds to the header in the server\n",
    "        assert list(col_type.keys()) == self.header_table, f'The header ({self.header_table}) of the table and the table in the Server ({list(col_type.keys())}) do not match!'\n",
    "\n",
    "        \n",
    "        table_list = list()\n",
    "\n",
    "        #cast the correct types to the local table\n",
    "        for col in self.header_table:\n",
    "            to_type = col_type[col] #get the stored type recast function from the col_type dictionary\n",
    "            self.table[col] = [to_type(el) for el in self.table[col]] #recast each element of the column\n",
    "            table_list.append([col] + self.table[col]) #save a copy and add the header to the column\n",
    "            \n",
    "        table_list = list(zip(*table_list)) #rebuild the table from the recasted columns (list of lists)\n",
    "        \n",
    "        return table_list\n",
    "\n",
    "    def sql_query_maker(self):\n",
    "        #add the first part of the query with table name and the rest\n",
    "        sql_query = f\"INSERT INTO {self.table_name} ({', '.join(self.header_table)}) VALUES (\"\n",
    "        first_parameter = '{}'\n",
    "        sql_query += first_parameter\n",
    "        \n",
    "        #for each element in the header add the parametric question mark (except for the first, thus -1)\n",
    "        for i in range(len(self.header_table)-1):\n",
    "            sql_query += \", {}\"\n",
    "        sql_query += \")\" #close the row to upload\n",
    "\n",
    "        return sql_query\n",
    "\n",
    "    def delete_previous_vals_from_table(self, table_name):\n",
    "        #try to delete the values from the table considered to upload\n",
    "        try:\n",
    "            self.cursor.execute(f'DELETE FROM {table_name}')\n",
    "            \n",
    "        #Every data in the hierarchy of the table will be deleted to avoid the Integrity Error\n",
    "        except pyodbc.IntegrityError as ierr:\n",
    "            #looking for the table to DELETE FROM in the error with regex\n",
    "            table_prefix = self.db[:self.db.rfind('_')]\n",
    "            start_idx = re.search(f'The conflict occurred in database \"{self.db}\", table \"{table_prefix}\\.', str(ierr)).end()\n",
    "            end_idx = str(ierr)[start_idx:].find('\"')+start_idx\n",
    "            \n",
    "            new_table = str(ierr)[start_idx:end_idx]\n",
    "            new_table_name = \"[\"+new_table+\"]\"\n",
    "            \n",
    "            #recursively remove from the tables in the higher hierarchy\n",
    "            self.delete_previous_vals_from_table(new_table_name)\n",
    "            #retry removing from the table (it should work now)\n",
    "            self.cursor.execute(f'DELETE FROM {table_name}')\n",
    "            \n",
    "    def insert_into_table(self):\n",
    "        #getting the query\n",
    "        model_sql_query = self.sql_query_maker()\n",
    "        #removing all the values from table to upload it\n",
    "        self.delete_previous_vals_from_table(self.table_name)\n",
    "        \n",
    "        print(\"Query:\\n\" + model_sql_query.format(*'?'*len(self.header_table)))\n",
    "        \n",
    "        sql_query = ''\n",
    "\n",
    "        #tqdm gives the progress bar, I looped across the rows (avoiding the header)\n",
    "        for n, row in enumerate(tqdm(self.table[1:], ascii=True, desc='Uploading Progress')):\n",
    "            tupla = tuple(el for el in row) #making the row a tuple if it is not\n",
    "            \n",
    "            current_query = model_sql_query.format(*tupla)+';\\n' # inserting values into the query\n",
    "            sql_query += current_query # adding up the current query to the others up until 100 queries\n",
    "                        \n",
    "            # To commit every 100 records (in case it crashes and I avoid the delete statement to finish uploading later)\n",
    "            # It avoids to commit at the first row but it commits after the last\n",
    "            # (len-2 because one is the header, the other is the index of the last element in a zero indexing base)\n",
    "            if (n == (n // 100) * 100) and n != 0 or n == len(self.table) - 2:\n",
    "                \n",
    "                # Try to reconnect at least 10 times if the execution fails\n",
    "                for attempt in range(10):\n",
    "                    try:\n",
    "                        #executing the 100 queries\n",
    "                        self.cursor.execute(sql_query)\n",
    "                        break\n",
    "\n",
    "                    #if it reaches the 10th execution raise the error I blocked\n",
    "                    except Exception as e:\n",
    "                        if attempt == 9:\n",
    "                            print(sql_query)\n",
    "                            raise e\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                self.conn.commit() #either way commit everything\n",
    "                sql_query = '' #reset the query so that it a new group of queries can be committed\n",
    "                \n",
    "        #commit at the end\n",
    "        self.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c7c670a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "INSERT INTO [Geography] (GeoId, Region, CountryCode, CountryName, Continents) VALUES (?, ?, ?, ?, ?)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Progress: 100%|############################################################| 76/76 [00:00<00:00, 5395.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "INSERT INTO [Subject] (SubjectId, Description) VALUES (?, ?)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Progress: 100%|#########################################################| 412/412 [00:00<00:00, 10089.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "INSERT INTO [Organization] (OrganizationId, GroupId, QuizId, SchemeOfWorkId) VALUES (?, ?, ?, ?)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Progress: 100%|######################################################| 24640/24640 [00:03<00:00, 7333.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "INSERT INTO [Date] (DateId, Dates, Year, Month, Day, Quarter) VALUES (?, ?, ?, ?, ?, ?)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Progress: 100%|##########################################################| 596/596 [00:00<00:00, 7413.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "INSERT INTO [User] (UserId, DateId, GeoId, Gender) VALUES (?, ?, ?, ?)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Progress: 100%|######################################################| 13630/13630 [00:01<00:00, 8581.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "INSERT INTO [Answers] (AnswerId, QuestionId, AnswerValue, CorrectAnswer, IsCorrect, Confidence, UserId, OrganizationId, DateId, SubjectId) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Progress: 100%|####################################################| 538835/538835 [01:30<00:00, 5924.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# upload all tables in the dictionary created (table names and tables were the input in the dict creation)\n",
    "for table_name in table_names:\n",
    "    Upload_Table(tables[table_name], table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70441223",
   "metadata": {},
   "source": [
    "# Total Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "38ec3927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:02:17.402533\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now() # to measure total execution time\n",
    "print(f'Duration: {(end_time - start_time)}') # around 2:20 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
